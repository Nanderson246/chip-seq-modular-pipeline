{
  "hash": "14220285952e34cf46df08078bb34ede",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"🔄 Pipeline 1: QC & Preprocessing Modules\"\n---\n\n## 🔄 Pipeline 1: QC & Preprocessing Modules\n\n## 🧬 Supported Data Types\n\nThis pipeline is designed for **ChIP-seq** and **ATAC-seq** data preprocessing. It includes:\n\n-   Adapter trimming (`cutadapt`)\n-   Parallel quality control (`FastQC`)\n-   Optional spike-in filtering\n-   Mitochondrial read removal\n-   Blacklist region filtering (ENCODE)\n-   Clean alignment with BWA and BAM post-processing\n\nBy supporting these steps, the pipeline ensures high-quality, reproducible inputs for downstream peak calling or chromatin accessibility analysis.\n\n> 🔁 While optimized for ChIP-seq, the pipeline is fully compatible with ATAC-seq experiments.\n\n\n\nScripts: `01_init_directories.sh` to `11_Renaming_bam.sh`\n\n``` bash\nmodules/pipeline1\\$ tree . \n├── 01_init_directories.sh \n├── 02_reference_check.sh \n├── 03_input_fetch.sh \n├── 04_fastqc_parallel.sh \n├── 05_05_Cutadapt_trimming_phix_parallel.sh \n├── 06_fastqc_trimmed_parallel.sh \n├── 07_spike_detect.sh \n├── 08_alignment_bwa_spike.sh \n├── 09_readgroups_add.sh \n├── 10_bam_cleaning.sh \n├── 10_plot_spike_qc_summary.R \n└── 11_Renaming_bam.sh\n```\nGreat structure! Given the flow of your Quarto document, the best place to add the **usage documentation** for `run_pipeline1.sh` would be **after** the `## 🧬 Supported Data Types` section and **before** the `### 🔧 Modules` section.\n\nThis keeps your document logically organized:\n\n1. **Intro**\n2. **What data it supports**\n3. **How to run it (Usage) ✅**\n4. **What each module does**\n5. **What the outputs are**\n\n---\n\n### ✅ Suggested Update (add this block in your `.qmd` file):\n\n````markdown\n### 🚀 Usage: `run_pipeline1.sh`\n\nThis script is the entry point for Pipeline 1 and supports both default and customized executions.\n\n#### ✅ Default Run\n\nRun with all defaults:\n```bash\nbash run_pipeline1.sh\n````\n\nThis uses:\n\n* `THREADS = 4`\n* `REFERENCE = hg38`\n* `ADAPTER = tn5_truseq`\n* `PLATFORM = ILLUMINA`\n* `MAPPING = metadata/mapping.tsv`\n* `REPORT_FORMAT = human`\n\n#### 🔧 Full Custom Run\n\nExample of overriding all defaults:\n\n```bash\nbash run_pipeline1.sh -t 8 -r mm10 -a tn5_nextera -p IONTORRENT -m data/sample_metadata.tsv -f csv\n```\n\nOverrides:\n\n* `-t 8`: 8 threads\n* `-r mm10`: mouse genome\n* `-a tn5_nextera`: alternative adapter\n* `-p IONTORRENT`: sequencing platform\n* `-m data/sample_metadata.tsv`: custom mapping file\n* `-f csv`: report format\n\n#### ℹ️ Help\n\nFor option details:\n\n```bash\nbash run_pipeline1.sh --help\n```\n\n\n### 🔧 Modules\n\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption><strong>🔧 Modules Overview</strong></caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Script </th>\n   <th style=\"text-align:left;\"> Purpose </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 01_init_directories.sh </td>\n   <td style=\"text-align:left;\"> Creates necessary directory structure. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 02_reference_check.sh </td>\n   <td style=\"text-align:left;\"> Validates presence of genome reference files. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 03_input_fetch.sh </td>\n   <td style=\"text-align:left;\"> Fetches and decompresses user-supplied FASTQ files. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 04_fastqc_parallel.sh </td>\n   <td style=\"text-align:left;\"> Runs FastQC and generates quality reports. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 05_Cutadapt_trimming_phix_parallel.sh </td>\n   <td style=\"text-align:left;\"> Trims adapters and low-quality bases using Cutadapt. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 06_fastqc_trimmed_parallel.sh </td>\n   <td style=\"text-align:left;\"> Runs FastQC on trimmed reads. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 07_spike_detect.sh </td>\n   <td style=\"text-align:left;\"> Detects exogenous spike-in if not provided. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 08_alignment_bwa_spike.sh </td>\n   <td style=\"text-align:left;\"> Aligns reads using BWA and checks spike content. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 09_readgroups_add.sh </td>\n   <td style=\"text-align:left;\"> Adds read group metadata using Picard. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 10_bam_cleaning.sh </td>\n   <td style=\"text-align:left;\"> Cleans and indexes BAMs; performs spike-in QC. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 11_Renaming_bam.sh </td>\n   <td style=\"text-align:left;\"> Renames BAMs using mapping.tsv for grouping. </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n\n### 📁 Output Folders\n\nresults/: Raw outputs and intermediate files.\n\nanalysis/Renamed_Cleaned: Cleaned and filtered BAMs for downstream usage.\n\nresults/\n\n``` bash\nresults/Filtered$ tree \n\n├── BAM}\n├── Filtered\n├        ├── Cleaned  ✅ here are the cleaned BAM that will be renamed. │\n├        ├── Deduplicated\n├        └── Metrics\n├── QC_fastqc\n├── QC_spike_plots\n├── QC_trimmed_fastqc\n├── spike_analysis\n└── Trimmed\n```\n\n------------------------------------------------------------------------\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}